{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8988e25b-9c79-466e-8ea4-808ca68073f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Gemma2ForSequenceClassification, BitsAndBytesConfig, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f7fc2f-27d0-4de9-a2d5-7fef5660bfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    \"_load_in_4bit\": False,\n",
    "    \"_load_in_8bit\": True,\n",
    "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
    "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
    "    \"bnb_4bit_quant_type\": \"fp4\",\n",
    "    \"bnb_4bit_use_double_quant\": False,\n",
    "    \"llm_int8_enable_fp32_cpu_offload\": False,\n",
    "    \"llm_int8_has_fp16_weight\": False,\n",
    "    \"llm_int8_skip_modules\": None,\n",
    "    \"llm_int8_threshold\": 6.0,\n",
    "    \"load_in_4bit\": False,\n",
    "    \"load_in_8bit\": True,\n",
    "    \"quant_method\": \"bitsandbytes\"\n",
    "  }\n",
    "\n",
    "bnb_cfg = BitsAndBytesConfig(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839807b3-03f6-4f6e-898f-3634933a7d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:57<00:00, 14.39s/it]\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    'unsloth/gemma-2-9b-it',\n",
    "    #quantization_config=bnb_cfg,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2241082e-e3cc-4a78-8572-65f6f47e8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, 'lmsys-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a95d3af-53cf-4ec9-bfbc-e207acd068f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86f458a-1fb4-494d-8b0d-cf8be2059c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score = torch.nn.Linear(in_features=3584, out_features=2, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d87183eb-0382-4d09-be2e-5d680ba658b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('lmsys-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "291e035d-a474-4fc3-a388-9dd245078b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MAIN-8BIT-LMSYS-PRETRAIN/tokenizer_config.json',\n",
       " 'MAIN-8BIT-LMSYS-PRETRAIN/special_tokens_map.json',\n",
       " 'MAIN-8BIT-LMSYS-PRETRAIN/tokenizer.model',\n",
       " 'MAIN-8BIT-LMSYS-PRETRAIN/added_tokens.json',\n",
       " 'MAIN-8BIT-LMSYS-PRETRAIN/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('MAIN-8BIT-LMSYS-PRETRAIN')\n",
    "tokenizer.save_pretrained('MAIN-8BIT-LMSYS-PRETRAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67259fe-478e-41cf-8c3c-dff3ba0c0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.38s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    'MAIN-8BIT-LMSYS-PRETRAIN',\n",
    "    quantization_config=bnb_cfg,\n",
    "    num_labels=2,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd45a3c-2eb9-4319-8f45-451b4d9f3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('MAIN-8BIT-LMSYS-PRETRAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f3a946-f886-4b60-a7bd-c689bb516fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN/tokenizer_config.json',\n",
       " 'QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN/special_tokens_map.json',\n",
       " 'QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN/tokenizer.model',\n",
       " 'QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN/added_tokens.json',\n",
       " 'QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN')\n",
    "tokenizer.save_pretrained('QUANTIZED-MAIN-8BIT-LMSYS-PRETRAIN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-311venv_kotov]",
   "language": "python",
   "name": "conda-env-.mlspace-311venv_kotov-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
