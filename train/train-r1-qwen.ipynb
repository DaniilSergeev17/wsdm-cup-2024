{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.47.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: bitsandbytes==0.45.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (0.45.0)\n",
      "Requirement already satisfied: accelerate==1.2.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: peft==0.14.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (0.14.0)\n",
      "Requirement already satisfied: datasets==3.2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: ftfy==6.3.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: pyarrow==18.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (18.1.0)\n",
      "Requirement already satisfied: chardet==5.2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (4.67.1)\n",
      "Requirement already satisfied: torch in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from bitsandbytes==0.45.0) (2.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from bitsandbytes==0.45.0) (4.12.2)\n",
      "Requirement already satisfied: psutil in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from accelerate==1.2.1) (5.9.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (3.11.9)\n",
      "Requirement already satisfied: wcwidth in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from ftfy==6.3.1) (0.2.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from requests->transformers==4.47.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from requests->transformers==4.47.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from requests->transformers==4.47.1) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from sympy==1.13.1->torch->bitsandbytes==0.45.0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from jinja2->torch->bitsandbytes==0.45.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"transformers==4.47.1\" \"bitsandbytes==0.45.0\" \"accelerate==1.2.1\" \"peft==0.14.0\" \"datasets==3.2.0\" \"ftfy==6.3.1\" \"pyarrow==18.1.0\" \"chardet==5.2.0\" \"charset-normalizer==3.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "import ftfy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, concatenate_datasets, Features, Value\n",
    "\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "VER = '17-8BIT-R1-QWEN-MODEL-99.9PERCENT-LEFTSIDE-LMSYS-AND-33K-EXTRA-DATA-MAXLEN2200-R64-A4-BF16'\n",
    "\n",
    "# --- lmsys extra data ---\n",
    "USE_ULTRAFEEDBACK = False\n",
    "USE_33K = True\n",
    "USE_LMSYS = True\n",
    "USE_CONCAT_DATA = True\n",
    "\n",
    "# --- additional features ---\n",
    "USE_LEFTSIDE_TRUNCATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = 'secret'\n",
    "os.environ['WANDB_PROJECT'] = 'WSDM Qwen2.5-7b-it'\n",
    "os.environ['WANDB_NOTES'] = f'WSDM Qwen2.5-7b-it LoRA Training VER-{VER}'\n",
    "os.environ['WANDB_NAME'] = f'ft-qwen2.5-wsdm-ver-{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = 'output'\n",
    "    checkpoint: str = 'R1-QWEN7B'\n",
    "    max_length: int = 2200\n",
    "    n_splits: int = 1000\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = 'adamw_8bit'\n",
    "    per_device_train_batch_size: int = 16\n",
    "    gradient_accumulation_steps: int = 1\n",
    "    per_device_eval_batch_size: int = 4\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 0\n",
    "    lr: float = 2e-4\n",
    "    warmup_ratio: float = 0.025\n",
    "    lora_r: int = 64\n",
    "    lora_alpha: float = 4.\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = 'none'\n",
    "    num_labels: int = 2\n",
    "    hdim: int = 3584\n",
    "    head_dropout: float = 0.1\n",
    "    label_smoothing_alpha: float = 0.\n",
    "    seed: int = 0xFACED\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f'output-{VER}',\n",
    "    overwrite_output_dir=True,\n",
    "    report_to='wandb',\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=1,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='steps',\n",
    "    save_steps=1000,\n",
    "    optim=config.optim_type,\n",
    "    bf16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    seed=config.seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.checkpoint)\n",
    "tokenizer.add_eos_token = True\n",
    "if USE_LEFTSIDE_TRUNCATION:\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0a65f3c6604d2785c86caaf5272ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=config.num_labels,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForSequenceClassification(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(152064, 3584)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=18944, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=18944, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=18944, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=18944, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=3584, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=3584, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 161,487,872 || all params: 7,232,114,176 || trainable%: 2.2329\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_parquet('data/wsdm-original.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CONCAT_DATA:\n",
    "    ds_concat =  Dataset.from_parquet('data/combined-lmsys-and-33k.parquet')\n",
    "\n",
    "    ds = ds.remove_columns(['id', 'model_a', 'model_b', 'language'])\n",
    "    \n",
    "    ds = ds.cast(Features({\n",
    "        'prompt': Value('string'),\n",
    "        'response_a': Value('string'),\n",
    "        'response_b': Value('string'),\n",
    "        'winner': Value('string')\n",
    "    }))\n",
    "\n",
    "    ds = concatenate_datasets([ds, ds_concat])\n",
    "    \n",
    "    ds = ds.shuffle(seed=0xFACED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = ['<prompt>: ' + self.process_text(t) for t in batch['prompt']]\n",
    "        response_a = ['\\n\\n<response_a>: ' + self.process_text(t) for t in batch['response_a']]\n",
    "        response_b = ['\\n\\n<response_b>: ' + self.process_text(t) for t in batch['response_b']]\n",
    "        \n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "        \n",
    "        labels = []\n",
    "        for win in batch['winner']:\n",
    "            if win in ('model_a', 'winner_a'):\n",
    "                label = 0\n",
    "            elif win in ('model_b', 'winner_b'):\n",
    "                label = 1\n",
    "            labels.append(label)\n",
    "            \n",
    "        return {**tokenized, 'labels': labels}\n",
    "\n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return ftfy.fix_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)\n",
    "ds = ds.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response_a', 'response_b', 'winner', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 102840\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n",
    "    return {'acc': acc, 'log_loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\n",
    "    (\n",
    "        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n",
    "        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n",
    "    ) \n",
    "    for fold_idx in range(config.n_splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, eval_idx = folds[config.fold_idx]\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds.select(train_idx),\n",
    "    eval_dataset=ds.select(eval_idx),\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlightsource-\u001b[0m (\u001b[33mlightsource-unk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/danila_workflow/CURRENT-WSDM/wandb/run-20250127_220247-lbn0fi0a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lightsource-unk/WSDM%20Qwen2.5-7b-it/runs/lbn0fi0a' target=\"_blank\">output-17-8BIT-R1-QWEN-MODEL-99.9PERCENT-LEFTSIDE-LMSYS-AND-33K-EXTRA-DATA-MAXLEN2200-R64-A4-BF16</a></strong> to <a href='https://wandb.ai/lightsource-unk/WSDM%20Qwen2.5-7b-it' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lightsource-unk/WSDM%20Qwen2.5-7b-it' target=\"_blank\">https://wandb.ai/lightsource-unk/WSDM%20Qwen2.5-7b-it</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lightsource-unk/WSDM%20Qwen2.5-7b-it/runs/lbn0fi0a' target=\"_blank\">https://wandb.ai/lightsource-unk/WSDM%20Qwen2.5-7b-it/runs/lbn0fi0a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='6422' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  16/6422 03:06 < 23:40:59, 0.08 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "login(token=\"secret\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=f\"output-{VER}/checkpoint-6422\",\n",
    "    repo_id=\"lightsource/wsdm-qwen-r1-adapter-lmsys-and-comp-2200-int8-0.XXX-w-tta\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-311venv_kotov]",
   "language": "python",
   "name": "conda-env-.mlspace-311venv_kotov-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
