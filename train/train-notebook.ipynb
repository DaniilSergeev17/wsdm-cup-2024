{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.47.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: bitsandbytes==0.45.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (0.45.0)\n",
      "Requirement already satisfied: accelerate==1.2.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: peft==0.14.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (0.14.0)\n",
      "Requirement already satisfied: datasets==3.2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: ftfy==6.3.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: pyarrow==18.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (18.1.0)\n",
      "Requirement already satisfied: chardet==5.2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from transformers==4.47.1) (4.67.1)\n",
      "Requirement already satisfied: torch in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from bitsandbytes==0.45.0) (2.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from bitsandbytes==0.45.0) (4.12.2)\n",
      "Requirement already satisfied: psutil in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from accelerate==1.2.1) (5.9.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from datasets==3.2.0) (3.11.9)\n",
      "Requirement already satisfied: wcwidth in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from ftfy==6.3.1) (0.2.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from requests->transformers==4.47.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from requests->transformers==4.47.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from requests->transformers==4.47.1) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from torch->bitsandbytes==0.45.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from sympy==1.13.1->torch->bitsandbytes==0.45.0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jovyan/.mlspace/envs/311venv_kotov/lib/python3.12/site-packages (from jinja2->torch->bitsandbytes==0.45.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"transformers==4.47.1\" \"bitsandbytes==0.45.0\" \"accelerate==1.2.1\" \"peft==0.14.0\" \"datasets==3.2.0\" \"ftfy==6.3.1\" \"pyarrow==18.1.0\" \"chardet==5.2.0\" \"charset-normalizer==3.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "import ftfy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, concatenate_datasets, Features, Value\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "VER = '13-REVERSED-8BIT-TOP5-LMSYS-MODEL-99.9PERCENT-CUSTOM-HEAD-LEFTSIDE-CONCAT-NO-EXTRA-DATA-MAXLEN2200-R64-A4-BF16'\n",
    "\n",
    "# --- was used in init checkpoint ---\n",
    "USE_ULTRAFEEDBACK = False\n",
    "USE_33K = False\n",
    "USE_LMSYS = False\n",
    "USE_CONCAT_DATA = False\n",
    "\n",
    "# --- new extra data ---\n",
    "USE_ORPO44K = False # don't work for top-5 init checkpoint\n",
    "USE_PREV_PSEUDOLABELS = False\n",
    "\n",
    "# --- my soft pseudolabeled data ---\n",
    "USE_PUBLIC_8K = False\n",
    "USE_MY_PL = False\n",
    "MY_PL_FRAC = 1\n",
    "\n",
    "# --- my hard pseudolabeled data ---\n",
    "USE_MY_HARD_PL = False\n",
    "\n",
    "# --- select init checkpoint ---\n",
    "USE_LMSYS_MODEL = True\n",
    "USE_FSFAIRX = False # no reason to test it\n",
    "\n",
    "# --- additional features ---\n",
    "USE_LEFTSIDE_TRUNCATION = True\n",
    "USE_PROMPT_PREFIX = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = 'secret'\n",
    "os.environ['WANDB_PROJECT'] = 'WSDM Gemma2-9b-it'\n",
    "os.environ['WANDB_NOTES'] = f'WSDM Gemma2-9b-it LoRA Training VER-{VER}'\n",
    "os.environ['WANDB_NAME'] = f'ft-gemma2-wsdm-ver-{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = 'output'\n",
    "    checkpoint: str = 'unsloth/gemma-2-9b-it-bnb-4bit'\n",
    "    old_path: str = 'TOP5-MODEL/QUANTIZED-TOP5-LMSYS-8BIT'\n",
    "    max_length: int = 2200\n",
    "    n_splits: int = 1000\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = 'adamw_8bit'\n",
    "    per_device_train_batch_size: int = 8\n",
    "    gradient_accumulation_steps: int = 2\n",
    "    per_device_eval_batch_size: int = 2\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 0\n",
    "    lr: float = 2e-4\n",
    "    warmup_ratio: float = 0.025\n",
    "    lora_r: int = 64\n",
    "    lora_alpha: float = 4.\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = 'none'\n",
    "    num_labels: int = 2\n",
    "    hdim: int = 3584\n",
    "    head_dropout: float = 0.1\n",
    "    label_smoothing_alpha: float = 0.\n",
    "    seed: int = 0xFACED\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f'output-{VER}',\n",
    "    overwrite_output_dir=True,\n",
    "    report_to='wandb',\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=1,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='steps',\n",
    "    save_steps=1000 if not USE_MY_PL else 10000,\n",
    "    optim=config.optim_type,\n",
    "    bf16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    seed=config.seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.checkpoint)\n",
    "tokenizer.add_eos_token = True\n",
    "if USE_LEFTSIDE_TRUNCATION:\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ac3b5519d5480e988ccd0f671bdfae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not USE_LMSYS_MODEL and not USE_FSFAIRX:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config.checkpoint,\n",
    "        num_labels=config.num_labels,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map='auto',\n",
    "    )\n",
    "    model.score = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(config.head_dropout),\n",
    "        torch.nn.Linear(config.hdim, config.hdim // 2),\n",
    "        torch.nn.Dropout(config.head_dropout),\n",
    "        torch.nn.GELU(),\n",
    "        torch.nn.Linear(config.hdim // 2, config.num_labels),\n",
    "    ).cuda().bfloat16()\n",
    "elif USE_LMSYS_MODEL:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config.old_path,\n",
    "        num_labels=config.num_labels,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map='auto',\n",
    "    )\n",
    "    model.score = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(config.head_dropout),\n",
    "        torch.nn.Linear(config.hdim, config.hdim // 2),\n",
    "        torch.nn.Dropout(config.head_dropout),\n",
    "        torch.nn.GELU(),\n",
    "        torch.nn.Linear(config.hdim // 2, config.num_labels),\n",
    "    ).cuda().bfloat16()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.old_path)\n",
    "    tokenizer.add_eos_token = True\n",
    "    if USE_LEFTSIDE_TRUNCATION:\n",
    "        tokenizer.padding_side = 'left'\n",
    "        tokenizer.truncation_side = 'left'\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForSequenceClassification(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-41): 42 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2Attention(\n",
       "              (q_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=4096, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=3584, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=14336, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): Linear(in_features=3584, out_features=1792, bias=True)\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): GELU(approximate='none')\n",
       "          (4): Linear(in_features=1792, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=3584, out_features=1792, bias=True)\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): GELU(approximate='none')\n",
       "            (4): Linear(in_features=1792, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 222,500,098 || all params: 9,470,633,988 || trainable%: 2.3494\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_parquet('data/wsdm-original.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_ORPO44K:\n",
    "    ds_orpo = Dataset.from_parquet('data/orpo-dpo-44k-for-wsdm.parquet')\n",
    "    ds_orpo = ds_orpo.remove_columns(['__index_level_0__'])\n",
    "\n",
    "    ds = ds.remove_columns(['id', 'model_a', 'model_b', 'language'])\n",
    "    \n",
    "    ds = ds.cast(Features({\n",
    "        'prompt': Value('string'),\n",
    "        'response_a': Value('string'),\n",
    "        'response_b': Value('string'),\n",
    "        'winner': Value('string')\n",
    "    }))\n",
    "\n",
    "    ds = concatenate_datasets([ds, ds_orpo])\n",
    "\n",
    "    ds = ds.shuffle(seed=0xFACED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PUBLIC_8K:\n",
    "    ds_public_8k = Dataset.from_parquet('data/wsdm-pseudolabeled/8k_pseudolabeled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MY_PL:\n",
    "    ds_my_pl = Dataset.from_parquet('data/wsdm-pseudolabeled/huuuuuge_pseudolabeled_df.parquet')\n",
    "    if MY_PL_FRAC != 1:\n",
    "        ds_my_pl = ds_my_pl.filter(lambda example, idx: idx % (1 / MY_PL_FRAC) == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MY_HARD_PL:\n",
    "    ds_hard = Dataset.from_parquet('data/wsdm-pseudolabeled/wsdm_pseudolabeled_from_my100perc_thold_0.95.parquet')\n",
    "\n",
    "    ds = ds.remove_columns(['id', 'model_a', 'model_b', 'language'])\n",
    "    \n",
    "    ds = ds.cast(Features({\n",
    "        'prompt': Value('string'),\n",
    "        'response_a': Value('string'),\n",
    "        'response_b': Value('string'),\n",
    "        'winner': Value('string')\n",
    "    }))\n",
    "\n",
    "    ds = concatenate_datasets([ds, ds_hard])\n",
    "    \n",
    "    ds = ds.shuffle(seed=0xFACED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CONCAT_DATA:\n",
    "    ds_concat =  Dataset.from_parquet('data/combined-lmsys-and-33k.parquet')\n",
    "\n",
    "    ds = ds.remove_columns(['id', 'model_a', 'model_b', 'language'])\n",
    "    \n",
    "    ds = ds.cast(Features({\n",
    "        'prompt': Value('string'),\n",
    "        'response_a': Value('string'),\n",
    "        'response_b': Value('string'),\n",
    "        'winner': Value('string')\n",
    "    }))\n",
    "\n",
    "    ds = concatenate_datasets([ds, ds_concat])\n",
    "    \n",
    "    ds = ds.shuffle(seed=0xFACED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = ['<prompt>: ' + self.process_text(t) for t in batch['prompt']]\n",
    "        response_a = ['\\n\\n<response_a>: ' + self.process_text(t) for t in batch['response_b']] #rev\n",
    "        response_b = ['\\n\\n<response_b>: ' + self.process_text(t) for t in batch['response_a']] #rev\n",
    "        \n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "        \n",
    "        labels = []\n",
    "        for win in batch['winner']:\n",
    "            if win in ('model_a', 'winner_a'):\n",
    "                label = 1 # [0.99, 0.01] rev\n",
    "            elif win in ('model_b', 'winner_b'):\n",
    "                label = 0 # [0.01, 0.99] rev\n",
    "            labels.append(label)\n",
    "            \n",
    "        return {**tokenized, 'labels': labels}\n",
    "\n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return ftfy.fix_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)\n",
    "ds = ds.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'prompt', 'response_a', 'response_b', 'winner', 'model_a', 'model_b', 'language', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 48439\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomTokenizerPL:\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         tokenizer: PreTrainedTokenizerBase, \n",
    "#         max_length: int\n",
    "#     ) -> None:\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "        \n",
    "#     def __call__(self, batch: dict) -> dict:\n",
    "#         prompt = ['<prompt>: ' + self.process_text(t) for t in batch['prompt']]\n",
    "#         response_a = ['\\n\\n<response_a>: ' + self.process_text(t) for t in batch['response_a']]\n",
    "#         response_b = ['\\n\\n<response_b>: ' + self.process_text(t) for t in batch['response_b']]\n",
    "        \n",
    "#         texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "#         tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "        \n",
    "#         labels = batch['winner']\n",
    "            \n",
    "#         return {**tokenized, 'labels': labels}\n",
    "\n",
    "#     @staticmethod\n",
    "#     def process_text(text: str) -> str:\n",
    "#         return ftfy.fix_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode = CustomTokenizerPL(tokenizer, max_length=config.max_length)\n",
    "\n",
    "# if USE_PUBLIC_8K:\n",
    "#     ds_public_8k = ds_public_8k.map(encode, batched=True)\n",
    "# if USE_MY_PL:\n",
    "#     ds_my_pl = ds_my_pl.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.remove_columns(['prompt', 'response_a', 'response_b', 'winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if USE_PUBLIC_8K:\n",
    "#     ds_public_8k = ds_public_8k.remove_columns(['prompt', 'response_a', 'response_b', 'winner'])\n",
    "#     ds = concatenate_datasets([ds, ds_public_8k])\n",
    "    \n",
    "# if USE_MY_PL:\n",
    "#     ds_my_pl = ds_my_pl.remove_columns(['prompt', 'response_a', 'response_b', 'winner'])  \n",
    "#     ds = concatenate_datasets([ds, ds_my_pl])\n",
    "\n",
    "# if USE_PUBLIC_8K or USE_MY_PL:\n",
    "#     ds = ds.shuffle(seed=0xFACED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'prompt', 'response_a', 'response_b', 'winner', 'model_a', 'model_b', 'language', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 48439\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n",
    "    return {'acc': acc, 'log_loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\n",
    "    (\n",
    "        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n",
    "        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n",
    "    ) \n",
    "    for fold_idx in range(config.n_splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "#         labels = inputs.pop(\"labels\")\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs.get(\"logits\")\n",
    "#         loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "#         if return_outputs:\n",
    "#             return loss, outputs\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, eval_idx = folds[config.fold_idx]\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds.select(train_idx),\n",
    "    eval_dataset=ds.select(eval_idx),\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlightsource-\u001b[0m (\u001b[33mlightsource-unk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/danila_workflow/CURRENT-WSDM/wandb/run-20250121_101457-xer2yrbh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lightsource-unk/WSDM%20Gemma2-9b-it/runs/xer2yrbh' target=\"_blank\">output-13-REVERSED-8BIT-TOP5-LMSYS-MODEL-99.9PERCENT-CUSTOM-HEAD-LEFTSIDE-CONCAT-NO-EXTRA-DATA-MAXLEN2200-R64-A4-BF16</a></strong> to <a href='https://wandb.ai/lightsource-unk/WSDM%20Gemma2-9b-it' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lightsource-unk/WSDM%20Gemma2-9b-it' target=\"_blank\">https://wandb.ai/lightsource-unk/WSDM%20Gemma2-9b-it</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lightsource-unk/WSDM%20Gemma2-9b-it/runs/xer2yrbh' target=\"_blank\">https://wandb.ai/lightsource-unk/WSDM%20Gemma2-9b-it/runs/xer2yrbh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='3024' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  46/3024 14:35 < 16:27:46, 0.05 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "login(token=\"secret\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=f\"output-{VER}/checkpoint-3024\",  \n",
    "    repo_id=\"lightsource/wsdm-top5-adapter-trained-only-on-rev-comp-data-2200-int8-0.XXX-w-tta\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-311venv_kotov]",
   "language": "python",
   "name": "conda-env-.mlspace-311venv_kotov-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
